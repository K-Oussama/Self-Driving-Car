{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Assets/my_datasetimg.pickle', 'rb') as data:\n",
    "    dataset = pickle.load(data)\n",
    "X=np.array(dataset)\n",
    "\n",
    "with open('Assets/my_dataset.pickle', 'rb') as datakey:\n",
    "    datasetkey = pickle.load(datakey)\n",
    "Y=np.array(datasetkey)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 160, 320, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 78, 158, 24)       1824      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 37, 77, 36)        21636     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 37, 48)        43248     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 33, 64)        76864     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 29, 64)         102464    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9, 29, 64)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16704)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               1670500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,922,107\n",
      "Trainable params: 1,922,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(160, 320, 3)))\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', strides=(2, 2)))\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', strides=(2, 2)))\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='elu'))\n",
    "model.add(Conv2D(64, (5, 5), activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(10, activation='elu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=1.0e-4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "50/50 [==============================] - 13s 236ms/step - loss: 0.9007\n",
      "Epoch 2/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.6082\n",
      "Epoch 3/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.5495\n",
      "Epoch 4/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.5000\n",
      "Epoch 5/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.4227\n",
      "Epoch 6/70\n",
      "50/50 [==============================] - 12s 238ms/step - loss: 0.3800\n",
      "Epoch 7/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.3176\n",
      "Epoch 8/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.2878\n",
      "Epoch 9/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.2385\n",
      "Epoch 10/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.1899\n",
      "Epoch 11/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.1739\n",
      "Epoch 12/70\n",
      "50/50 [==============================] - 12s 237ms/step - loss: 0.1369\n",
      "Epoch 13/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.1120\n",
      "Epoch 14/70\n",
      "50/50 [==============================] - 12s 235ms/step - loss: 0.1049\n",
      "Epoch 15/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0822\n",
      "Epoch 16/70\n",
      "50/50 [==============================] - 12s 235ms/step - loss: 0.0774\n",
      "Epoch 17/70\n",
      "50/50 [==============================] - 12s 235ms/step - loss: 0.0691\n",
      "Epoch 18/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0551\n",
      "Epoch 19/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0504\n",
      "Epoch 20/70\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.0488\n",
      "Epoch 21/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0456\n",
      "Epoch 22/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0544\n",
      "Epoch 23/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0443\n",
      "Epoch 24/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0383\n",
      "Epoch 25/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0382\n",
      "Epoch 26/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0400\n",
      "Epoch 27/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0397\n",
      "Epoch 28/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0451\n",
      "Epoch 29/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0391\n",
      "Epoch 30/70\n",
      "50/50 [==============================] - 12s 230ms/step - loss: 0.0454\n",
      "Epoch 31/70\n",
      "50/50 [==============================] - 12s 231ms/step - loss: 0.0374\n",
      "Epoch 32/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0327\n",
      "Epoch 33/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0302\n",
      "Epoch 34/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0319\n",
      "Epoch 35/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0292\n",
      "Epoch 36/70\n",
      "50/50 [==============================] - 12s 231ms/step - loss: 0.0284\n",
      "Epoch 37/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0276\n",
      "Epoch 38/70\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.0278\n",
      "Epoch 39/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0326\n",
      "Epoch 40/70\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.0338\n",
      "Epoch 41/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0288\n",
      "Epoch 42/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0257\n",
      "Epoch 43/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0223\n",
      "Epoch 44/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0236\n",
      "Epoch 45/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0220\n",
      "Epoch 46/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0226\n",
      "Epoch 47/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0236\n",
      "Epoch 48/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0230\n",
      "Epoch 49/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0205\n",
      "Epoch 50/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0209\n",
      "Epoch 51/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0239\n",
      "Epoch 52/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0248\n",
      "Epoch 53/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0224\n",
      "Epoch 54/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0181\n",
      "Epoch 55/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0177\n",
      "Epoch 56/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0185\n",
      "Epoch 57/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0174\n",
      "Epoch 58/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0201\n",
      "Epoch 59/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0186\n",
      "Epoch 60/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0186\n",
      "Epoch 61/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0171\n",
      "Epoch 62/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0160\n",
      "Epoch 63/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0137\n",
      "Epoch 64/70\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0154\n",
      "Epoch 65/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0153\n",
      "Epoch 66/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0127\n",
      "Epoch 67/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0154\n",
      "Epoch 68/70\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0148\n",
      "Epoch 69/70\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0153\n",
      "Epoch 70/70\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.0138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c72f8c9430>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=70, batch_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Assets/model_15.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 224ms/step - loss: 0.0067\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "# clf = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1)\n",
    "# \n",
    "# X_train_flat = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "# clf.fit(X_train_flat, y_train)\n",
    "# \n",
    "# X_test_flat = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "# clf.score(X_test_flat, y_test)\n",
    "# \n",
    "# \n",
    "# joblib.dump(clf, 'Assets/model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
